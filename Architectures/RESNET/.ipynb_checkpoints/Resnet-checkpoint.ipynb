{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T14:08:16.145809Z",
     "iopub.status.busy": "2021-11-12T14:08:16.145499Z",
     "iopub.status.idle": "2021-11-12T14:08:18.414498Z",
     "shell.execute_reply": "2021-11-12T14:08:18.413512Z",
     "shell.execute_reply.started": "2021-11-12T14:08:16.145778Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:28:43.968987Z",
     "iopub.status.busy": "2021-11-12T13:28:43.968570Z",
     "iopub.status.idle": "2021-11-12T13:28:43.972563Z",
     "shell.execute_reply": "2021-11-12T13:28:43.971727Z",
     "shell.execute_reply.started": "2021-11-12T13:28:43.968957Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE=64\n",
    "num_epochs=5\n",
    "lr=1e-4\n",
    "class_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:29:46.301692Z",
     "iopub.status.busy": "2021-11-12T13:29:46.301378Z",
     "iopub.status.idle": "2021-11-12T13:29:52.815769Z",
     "shell.execute_reply": "2021-11-12T13:29:52.814811Z",
     "shell.execute_reply.started": "2021-11-12T13:29:46.301657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4434835fdc9741929176b47c391c1a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "tranform_train = transforms.Compose([transforms.Resize((256,480)), transforms.RandomHorizontalFlip(p=0.7), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "tranform_test = transforms.Compose([transforms.Resize((256,480)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "#prep the train, validation and test dataset\n",
    "torch.manual_seed(2021)\n",
    "train = torchvision.datasets.CIFAR10(\"data/\", train=True, download=True, transform=tranform_train) \n",
    "val_size = 10000 \n",
    "train_size = len(train) - val_size\n",
    "train, val = random_split(train, [train_size, val_size]) \n",
    "test = torchvision.datasets.CIFAR10(\"data/\", train=False, download=True, transform=tranform_test) \n",
    "\n",
    "#  train, val and test datasets to the dataloader\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T14:13:30.893986Z",
     "iopub.status.busy": "2021-11-12T14:13:30.893710Z",
     "iopub.status.idle": "2021-11-12T14:13:30.904804Z",
     "shell.execute_reply": "2021-11-12T14:13:30.904156Z",
     "shell.execute_reply.started": "2021-11-12T14:13:30.893957Z"
    }
   },
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,identitiy_downsample=None,stride=1):\n",
    "        super(block,self).__init__()\n",
    "\n",
    "        self.expansion = 4\n",
    "        self.conv1 =nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
    "        self.bnorm1 =nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 =nn.Conv2d(out_channels,out_channels,kernel_size=1,stride=stride,padding=1)\n",
    "        self.bnorm2 =nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 =nn.Conv2d(out_channels,out_channels*self.expansion, kernel_size=1,stride=1,padding=1)\n",
    "        self.bnorm3 =nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.idententity = identity_downsample\n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bnorm1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bnorm2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bnorm3(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identitiy)\n",
    "        #ADD the identitiy\n",
    "        x += identitiy\n",
    "        x =self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T14:19:31.265690Z",
     "iopub.status.busy": "2021-11-12T14:19:31.265248Z",
     "iopub.status.idle": "2021-11-12T14:19:31.272952Z",
     "shell.execute_reply": "2021-11-12T14:19:31.271930Z",
     "shell.execute_reply.started": "2021-11-12T14:19:31.265641Z"
    }
   },
   "outputs": [],
   "source": [
    "class Resnet(nn.Module): #For resnet 50 [ 3, ,4 , 6 ,3 ] no of blocks\n",
    "    def __init__(self,block,layers,image_channels,num_classes):\n",
    "        super(Resnet,self).__init__()\n",
    "        #initial layers\n",
    "        self.in_channels=64\n",
    "        self.conv1 = nn.Conv2d(in_channels=64, kernel_size = 7, stride = 2, padding=3)\n",
    "        self.bnorm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = self.RelU()\n",
    "        self.maxpool = nn.MaxPool2d(kerneL_size = 3, stride =2, padding =3 )\n",
    "        \n",
    "        #Resnet layers here\n",
    "        self.layer1= self.make_layer(block,layers[0],out_channels=64,stride=1)\n",
    "        self.layer2= self.make_layer(block,layers[1],out_channels=128,stride=2)\n",
    "        self.layer3= self.make_layer(block,layers[2],out_channels=256,stride=2)\n",
    "        self.layer4= self.make_layer(block,layers[3],out_channels=512,stride=2)\n",
    "       \n",
    "         \n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512*4,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self,x):\n",
    "    x=self.conv1(x)\n",
    "    x=self.bn1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.maxpool(x)\n",
    "    \n",
    "    x= self.layer1(x)\n",
    "    x= self.layer2(x)\n",
    "    x= self.layer3(x)\n",
    "    x= self.layer4(x)\n",
    "    \n",
    "    x= self.avgpool(x)\n",
    "    x= x.reshape(x.shape[0],-1)\n",
    "    x=self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer(self,block,num_residual_blocks,out_channels, stride):\n",
    "    identitiy_downsample = []\n",
    "    layers = []\n",
    "    \n",
    "    if stride !=1 or self.in_channels != out_channels * 4:\n",
    "        identitiy_downsample=nn.Sequential(nn.Con2d(self.in_channels,out_channels*4,kernel_size=1,\n",
    "                                                   stride=stride),\n",
    "                                          nn.BatchNorm2d(out_channels*4))\n",
    "        \n",
    "    layers.append(block(self.in_channels,64,identitiy_downsample,stride))\n",
    "    self.in_channels=out_channels*4    \n",
    "    \n",
    "    for i in range(num_residual_blocks-1):\n",
    "        layers.append(block(self.in_channels,out_channels)) #256->64,64*4 (256 again)\n",
    "    return nn.Sequential(*layers) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResneT50(img_channels=3,num_classes=10):\n",
    "    return Resnet(block[3,4,6,3], img_channels,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net=ResneT50()\n",
    "    x=torch.randn(2,3,224,224)\n",
    "    y=net(x).to('cuda')\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
