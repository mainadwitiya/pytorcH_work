{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport seaborn as sns\nimport numpy as np\nfrom torch.utils.data import random_split\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-11-12T14:08:16.145499Z","iopub.execute_input":"2021-11-12T14:08:16.145809Z","iopub.status.idle":"2021-11-12T14:08:18.414498Z","shell.execute_reply.started":"2021-11-12T14:08:16.145778Z","shell.execute_reply":"2021-11-12T14:08:18.413512Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nBATCH_SIZE=64\nnum_epochs=5\nlr=1e-4\nclass_size=10","metadata":{"execution":{"iopub.status.busy":"2021-11-12T13:28:43.968570Z","iopub.execute_input":"2021-11-12T13:28:43.968987Z","iopub.status.idle":"2021-11-12T13:28:43.972563Z","shell.execute_reply.started":"2021-11-12T13:28:43.968957Z","shell.execute_reply":"2021-11-12T13:28:43.971727Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tranform_train = transforms.Compose([transforms.Resize((256,480)), transforms.RandomHorizontalFlip(p=0.7), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\ntranform_test = transforms.Compose([transforms.Resize((256,480)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n#prep the train, validation and test dataset\ntorch.manual_seed(2021)\ntrain = torchvision.datasets.CIFAR10(\"data/\", train=True, download=True, transform=tranform_train) \nval_size = 10000 \ntrain_size = len(train) - val_size\ntrain, val = random_split(train, [train_size, val_size]) \ntest = torchvision.datasets.CIFAR10(\"data/\", train=False, download=True, transform=tranform_test) \n\n#  train, val and test datasets to the dataloader\ntrain_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T13:29:46.301378Z","iopub.execute_input":"2021-11-12T13:29:46.301692Z","iopub.status.idle":"2021-11-12T13:29:52.815769Z","shell.execute_reply.started":"2021-11-12T13:29:46.301657Z","shell.execute_reply":"2021-11-12T13:29:52.814811Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class block(nn.Module):\n    def __init__(self,in_channels,out_channels,identitiy_downsample=None,stride=1):\n        super(block,self).__init__()\n\n        self.expansion = 4\n        self.conv1 =nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0)\n        self.bnorm1 =nn.BatchNorm2d(out_channels)\n        self.conv2 =nn.Conv2d(out_channels,out_channels,kernel_size=1,stride=stride,padding=1)\n        self.bnorm2 =nn.BatchNorm2d(out_channels)\n        self.conv3 =nn.Conv2d(out_channels,out_channels*self.expansion, kernel_size=1,stride=1,padding=1)\n        self.bnorm3 =nn.BatchNorm2d(out_channels*self.expansion)\n        self.relu = nn.ReLU()\n        self.idententity = identity_downsample\n    def forward(self,x):\n        identity = x\n        \n        x = self.conv1(x)\n        x = self.bnorm1(x)\n        x = self.conv2(x)\n        x = self.bnorm2(x)\n        x = self.conv3(x)\n        x = self.bnorm3(x)\n        \n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identitiy)\n        #ADD the identitiy\n        x += identitiy\n        x =self.relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-12T14:13:30.893710Z","iopub.execute_input":"2021-11-12T14:13:30.893986Z","iopub.status.idle":"2021-11-12T14:13:30.904804Z","shell.execute_reply.started":"2021-11-12T14:13:30.893957Z","shell.execute_reply":"2021-11-12T14:13:30.904156Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Resnet(nn.Module): #For resnet 50 [ 3, ,4 , 6 ,3 ] no of blocks\n    def __init__(self,block,layers,image_channels,num_classes):\n        super(Resnet,self).__init__()\n        #initial layers\n        self.in_channels=64\n        self.conv1 = nn.Conv2d(in_channels=64, kernel_size = 7, stride = 2, padding=3)\n        self.bnorm1 = nn.BatchNorm2d(64)\n        self.relu = self.RelU()\n        self.maxpool = nn.MaxPool2d(kerneL_size = 3, stride =2, padding =3 )\n        \n        #Resnet layers here\n        #self.layer1=....\n        #self.layer2=....","metadata":{"execution":{"iopub.status.busy":"2021-11-12T14:19:31.265248Z","iopub.execute_input":"2021-11-12T14:19:31.265690Z","iopub.status.idle":"2021-11-12T14:19:31.272952Z","shell.execute_reply.started":"2021-11-12T14:19:31.265641Z","shell.execute_reply":"2021-11-12T14:19:31.271930Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def _make_layer(self,block,num_residual_blocks,out_channels, stride):\n    identitiy_downsample = []\n    layers = []\n     \n    ","metadata":{},"execution_count":null,"outputs":[]}]}